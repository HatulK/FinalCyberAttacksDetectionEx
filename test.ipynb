{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-13T12:57:06.441998400Z",
     "start_time": "2024-02-13T12:56:57.832989100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "\u001B[33mWARNING: Ignoring invalid distribution -orch (/home/porat/.local/lib/python3.10/site-packages)\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -orch (/home/porat/.local/lib/python3.10/site-packages)\u001B[0m\u001B[33m\r\n",
      "\u001B[0mRequirement already satisfied: nltk in ./.local/lib/python3.10/site-packages (3.8.1)\r\n",
      "Requirement already satisfied: datasets in ./.local/lib/python3.10/site-packages (2.16.1)\r\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.10/site-packages (4.36.2)\r\n",
      "Requirement already satisfied: torch in ./.local/lib/python3.10/site-packages (2.1.2)\r\n",
      "Requirement already satisfied: pandas in ./.local/lib/python3.10/site-packages (2.1.4)\r\n",
      "Requirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (3.5.1)\r\n",
      "Collecting seaborn\r\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\r\n",
      "Requirement already satisfied: scikit-learn in ./.local/lib/python3.10/site-packages (1.3.2)\r\n",
      "Requirement already satisfied: tqdm in ./.local/lib/python3.10/site-packages (4.65.0)\r\n",
      "Collecting wordcloud\r\n",
      "  Downloading wordcloud-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m511.1/511.1 KB\u001B[0m \u001B[31m2.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: ipywidgets in ./.local/lib/python3.10/site-packages (8.1.1)\r\n",
      "Collecting shap\r\n",
      "  Downloading shap-0.44.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (535 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m535.7/535.7 KB\u001B[0m \u001B[31m19.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting optuna\r\n",
      "  Using cached optuna-3.5.0-py3-none-any.whl (413 kB)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.local/lib/python3.10/site-packages (from nltk) (2023.10.3)\r\n",
      "Requirement already satisfied: joblib in ./.local/lib/python3.10/site-packages (from nltk) (1.3.2)\r\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (8.0.3)\r\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in ./.local/lib/python3.10/site-packages (from datasets) (0.3.7)\r\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.10/site-packages (from datasets) (3.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in ./.local/lib/python3.10/site-packages (from datasets) (0.20.2)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in ./.local/lib/python3.10/site-packages (from datasets) (2.31.0)\r\n",
      "Requirement already satisfied: packaging in ./.local/lib/python3.10/site-packages (from datasets) (23.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.local/lib/python3.10/site-packages (from datasets) (6.0.1)\r\n",
      "Requirement already satisfied: multiprocess in ./.local/lib/python3.10/site-packages (from datasets) (0.70.15)\r\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in ./.local/lib/python3.10/site-packages (from datasets) (2023.10.0)\r\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in ./.local/lib/python3.10/site-packages (from datasets) (14.0.2)\r\n",
      "Requirement already satisfied: xxhash in ./.local/lib/python3.10/site-packages (from datasets) (3.4.1)\r\n",
      "Requirement already satisfied: pyarrow-hotfix in ./.local/lib/python3.10/site-packages (from datasets) (0.6)\r\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.10/site-packages (from datasets) (1.26.2)\r\n",
      "Requirement already satisfied: aiohttp in ./.local/lib/python3.10/site-packages (from datasets) (3.9.1)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./.local/lib/python3.10/site-packages (from transformers) (0.15.0)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./.local/lib/python3.10/site-packages (from transformers) (0.4.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.local/lib/python3.10/site-packages (from torch) (11.0.2.54)\r\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.10/site-packages (from torch) (3.2.1)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.local/lib/python3.10/site-packages (from torch) (11.4.5.107)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch) (1.9)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.local/lib/python3.10/site-packages (from torch) (8.9.2.26)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.local/lib/python3.10/site-packages (from torch) (10.3.2.106)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.local/lib/python3.10/site-packages (from torch) (12.1.0.106)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: typing-extensions in ./.local/lib/python3.10/site-packages (from torch) (4.9.0)\r\n",
      "Requirement already satisfied: triton==2.1.0 in ./.local/lib/python3.10/site-packages (from torch) (2.1.0)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in ./.local/lib/python3.10/site-packages (from torch) (2.18.1)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch) (3.0.3)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.local/lib/python3.10/site-packages (from torch) (12.1.3.1)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.local/lib/python3.10/site-packages (from pandas) (2.8.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.local/lib/python3.10/site-packages (from pandas) (2023.3)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.local/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\r\n",
      "Requirement already satisfied: scipy>=1.5.0 in ./.local/lib/python3.10/site-packages (from scikit-learn) (1.11.1)\r\n",
      "Requirement already satisfied: pillow in /usr/lib/python3/dist-packages (from wordcloud) (9.0.1)\r\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in ./.local/lib/python3.10/site-packages (from ipywidgets) (4.0.9)\r\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in ./.local/lib/python3.10/site-packages (from ipywidgets) (3.0.9)\r\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/lib/python3/dist-packages (from ipywidgets) (5.1.1)\r\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/lib/python3/dist-packages (from ipywidgets) (7.31.1)\r\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.local/lib/python3.10/site-packages (from ipywidgets) (0.2.0)\r\n",
      "Collecting cloudpickle\r\n",
      "  Using cached cloudpickle-3.0.0-py3-none-any.whl (20 kB)\r\n",
      "Requirement already satisfied: numba in ./.local/lib/python3.10/site-packages (from shap) (0.58.1)\r\n",
      "Collecting slicer==0.0.7\r\n",
      "  Using cached slicer-0.0.7-py3-none-any.whl (14 kB)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in ./.local/lib/python3.10/site-packages (from optuna) (2.0.24)\r\n",
      "Collecting alembic>=1.5.0\r\n",
      "  Using cached alembic-1.13.1-py3-none-any.whl (233 kB)\r\n",
      "Collecting colorlog\r\n",
      "  Using cached colorlog-6.8.2-py3-none-any.whl (11 kB)\r\n",
      "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp->datasets) (21.2.0)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets) (3.3)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets) (2020.6.20)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.local/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\r\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in ./.local/lib/python3.10/site-packages (from numba->shap) (0.41.1)\r\n",
      "\u001B[33mWARNING: Ignoring invalid distribution -orch (/home/porat/.local/lib/python3.10/site-packages)\u001B[0m\u001B[33m\r\n",
      "\u001B[0mInstalling collected packages: wordcloud, slicer, colorlog, cloudpickle, alembic, shap, seaborn, optuna\r\n",
      "\u001B[33mWARNING: Ignoring invalid distribution -orch (/home/porat/.local/lib/python3.10/site-packages)\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -orch (/home/porat/.local/lib/python3.10/site-packages)\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -orch (/home/porat/.local/lib/python3.10/site-packages)\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -orch (/home/porat/.local/lib/python3.10/site-packages)\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -orch (/home/porat/.local/lib/python3.10/site-packages)\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -orch (/home/porat/.local/lib/python3.10/site-packages)\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -orch (/home/porat/.local/lib/python3.10/site-packages)\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -orch (/home/porat/.local/lib/python3.10/site-packages)\u001B[0m\u001B[33m\r\n",
      "\u001B[0mSuccessfully installed alembic-1.13.1 cloudpickle-3.0.0 colorlog-6.8.2 optuna-3.5.0 seaborn-0.13.2 shap-0.44.1 slicer-0.0.7 wordcloud-1.9.3\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "! /usr/bin/python3 -m pip install nltk datasets transformers torch pandas matplotlib seaborn scikit-learn tqdm wordcloud ipywidgets shap optuna seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "\u001B[33mWARNING: Ignoring invalid distribution -orch (/home/porat/.local/lib/python3.10/site-packages)\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution -orch (/home/porat/.local/lib/python3.10/site-packages)\u001B[0m\u001B[33m\r\n",
      "\u001B[0mRequirement already satisfied: Pillow in /usr/lib/python3/dist-packages (9.0.1)\r\n",
      "Collecting Pillow\r\n",
      "  Downloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.5/4.5 MB\u001B[0m \u001B[31m10.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m0:01\u001B[0m\r\n",
      "\u001B[?25h\u001B[33mWARNING: Ignoring invalid distribution -orch (/home/porat/.local/lib/python3.10/site-packages)\u001B[0m\u001B[33m\r\n",
      "\u001B[0mInstalling collected packages: Pillow\r\n",
      "\u001B[33mWARNING: Ignoring invalid distribution -orch (/home/porat/.local/lib/python3.10/site-packages)\u001B[0m\u001B[33m\r\n",
      "\u001B[0mSuccessfully installed Pillow-10.2.0\r\n"
     ]
    }
   ],
   "source": [
    "! /usr/bin/python3 -m pip install --upgrade Pillow"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T13:15:28.352891100Z",
     "start_time": "2024-02-13T13:15:22.471489500Z"
    }
   },
   "id": "4c25868b098d7c69"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing /home/porat/.local/lib/python3.10/site-packages/widgetsnbextension/static -> jupyter-js-widgets\r\n",
      "Up to date: /home/porat/.local/share/jupyter/nbextensions/jupyter-js-widgets/extension.js.LICENSE.txt\r\n",
      "Up to date: /home/porat/.local/share/jupyter/nbextensions/jupyter-js-widgets/extension.js.map\r\n",
      "Up to date: /home/porat/.local/share/jupyter/nbextensions/jupyter-js-widgets/extension.js\r\n",
      "- Validating: \u001B[32mOK\u001B[0m\r\n",
      "\r\n",
      "    To initialize this nbextension in the browser every time the notebook (or other app) loads:\r\n",
      "    \r\n",
      "          jupyter nbextension enable widgetsnbextension --user --py\r\n",
      "    \r\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\r\n",
      "      - Validating: \u001B[32mOK\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension install --user --py widgetsnbextension\n",
    "!jupyter nbextension enable --user --py widgetsnbextension"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-13T12:57:09.444606100Z",
     "start_time": "2024-02-13T12:57:08.622079900Z"
    }
   },
   "id": "75ec89bc5abb341d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fake News Detection\n",
    "\n",
    " In this notebook, we will use the `GonzaloA/fake_news` dataset to train a model to detect fake news. We will use the `transformers` library to fine-tune a BERT model on this task. We will also use the `optuna` library to perform hyperparameter optimization.  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b3e6bc472171985"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import optuna"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:03:32.969845100Z",
     "start_time": "2024-02-22T12:03:27.765270Z"
    }
   },
   "id": "7f733530f84a42b0"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/porat/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/porat/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'a',\n 'about',\n 'above',\n 'after',\n 'again',\n 'against',\n 'ain',\n 'all',\n 'am',\n 'an',\n 'and',\n 'any',\n 'are',\n 'aren',\n \"aren't\",\n 'as',\n 'at',\n 'be',\n 'because',\n 'been',\n 'before',\n 'being',\n 'below',\n 'between',\n 'both',\n 'but',\n 'by',\n 'can',\n 'couldn',\n \"couldn't\",\n 'd',\n 'did',\n 'didn',\n \"didn't\",\n 'do',\n 'does',\n 'doesn',\n \"doesn't\",\n 'doing',\n 'don',\n \"don't\",\n 'down',\n 'during',\n 'each',\n 'few',\n 'for',\n 'from',\n 'further',\n 'had',\n 'hadn',\n \"hadn't\",\n 'has',\n 'hasn',\n \"hasn't\",\n 'have',\n 'haven',\n \"haven't\",\n 'having',\n 'he',\n 'her',\n 'here',\n 'hers',\n 'herself',\n 'him',\n 'himself',\n 'his',\n 'how',\n 'i',\n 'if',\n 'in',\n 'into',\n 'is',\n 'isn',\n \"isn't\",\n 'it',\n \"it's\",\n 'its',\n 'itself',\n 'just',\n 'll',\n 'm',\n 'ma',\n 'me',\n 'mightn',\n \"mightn't\",\n 'more',\n 'most',\n 'mustn',\n \"mustn't\",\n 'my',\n 'myself',\n 'needn',\n \"needn't\",\n 'no',\n 'nor',\n 'not',\n 'now',\n 'o',\n 'of',\n 'off',\n 'on',\n 'once',\n 'only',\n 'or',\n 'other',\n 'our',\n 'ours',\n 'ourselves',\n 'out',\n 'over',\n 'own',\n 're',\n 's',\n 'same',\n 'shan',\n \"shan't\",\n 'she',\n \"she's\",\n 'should',\n \"should've\",\n 'shouldn',\n \"shouldn't\",\n 'so',\n 'some',\n 'such',\n 't',\n 'than',\n 'that',\n \"that'll\",\n 'the',\n 'their',\n 'theirs',\n 'them',\n 'themselves',\n 'then',\n 'there',\n 'these',\n 'they',\n 'this',\n 'those',\n 'through',\n 'to',\n 'too',\n 'under',\n 'until',\n 'up',\n 've',\n 'very',\n 'was',\n 'wasn',\n \"wasn't\",\n 'we',\n 'were',\n 'weren',\n \"weren't\",\n 'what',\n 'when',\n 'where',\n 'which',\n 'while',\n 'who',\n 'whom',\n 'why',\n 'will',\n 'with',\n 'won',\n \"won't\",\n 'wouldn',\n \"wouldn't\",\n 'y',\n 'you',\n \"you'd\",\n \"you'll\",\n \"you're\",\n \"you've\",\n 'your',\n 'yours',\n 'yourself',\n 'yourselves'}"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:03:33.209834100Z",
     "start_time": "2024-02-22T12:03:32.973818Z"
    }
   },
   "id": "cb3b2d10841370f5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load  and prepare the dataset\n",
    " We will use the `load_dataset` function from the `datasets` library to load the `GonzaloA/fake_news` dataset. We will then split the dataset into training, validation, and test sets. We will also clean the text by removing stopwords we discovered that the dataset contains a lot of stopwords, so we will remove them to reduce the noise in the data. \n",
    "  Since Bert can only handle sequences of up to 512 tokens, we will split the texts into chunks of 512 tokens. We will then tokenize the chunks using the BERT tokenizer."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40b639c4dd540469"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/porat/.local/lib/python3.10/site-packages/huggingface_hub/repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n"
     ]
    }
   ],
   "source": [
    "full_dataset = load_dataset('GonzaloA/fake_news')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:03:39.282367500Z",
     "start_time": "2024-02-22T12:03:33.362310800Z"
    }
   },
   "id": "1e4feaf5908e1eff"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# remove unnamed column\n",
    "full_dataset['train'] = full_dataset['train'].remove_columns('Unnamed: 0')\n",
    "full_dataset['validation'] = full_dataset['validation'].remove_columns('Unnamed: 0')\n",
    "full_dataset['test'] = full_dataset['test'].remove_columns('Unnamed: 0')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:03:39.292301100Z",
     "start_time": "2024-02-22T12:03:39.285844200Z"
    }
   },
   "id": "ed1d1c63f72a27a4"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "{'title': Value(dtype='string', id=None),\n 'text': Value(dtype='string', id=None),\n 'label': Value(dtype='int64', id=None)}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset['train'].info.features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:03:39.301240900Z",
     "start_time": "2024-02-22T12:03:39.294287800Z"
    }
   },
   "id": "19333fb6ae52e8a5"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in train dataset:\n",
      " title    0\n",
      "text     0\n",
      "label    0\n",
      "dtype: int64\n",
      "Missing values in validation dataset:\n",
      " title    0\n",
      "text     0\n",
      "label    0\n",
      "dtype: int64\n",
      "Missing values in test dataset:\n",
      " title    0\n",
      "text     0\n",
      "label    0\n",
      "dtype: int64\n",
      "Duplicates in train dataset:\n",
      " 0\n",
      "Duplicates in validation dataset:\n",
      " 0\n",
      "Duplicates in test dataset:\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame(full_dataset['train'])\n",
    "val_df = pd.DataFrame(full_dataset['validation'])\n",
    "test_df = pd.DataFrame(full_dataset['test'])\n",
    "# Check for missing values\n",
    "print(\"Missing values in train dataset:\\n\", train_df.isnull().sum())\n",
    "print(\"Missing values in validation dataset:\\n\", val_df.isnull().sum())\n",
    "print(\"Missing values in test dataset:\\n\", test_df.isnull().sum())\n",
    "# Check for duplicates\n",
    "print(\"Duplicates in train dataset:\\n\", train_df.duplicated().sum())\n",
    "print(\"Duplicates in validation dataset:\\n\", val_df.duplicated().sum())\n",
    "print(\"Duplicates in test dataset:\\n\", test_df.duplicated().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:03:42.256942Z",
     "start_time": "2024-02-22T12:03:39.303724300Z"
    }
   },
   "id": "4e60ff534ae2d458"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TITLE] token id:  50265\n",
      "[TEXT] token id:  50266\n"
     ]
    }
   ],
   "source": [
    "model_name = \"distilroberta-base\"  # bert-base-uncased\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "special_tokens = ['[TITLE]', '[TEXT]']\n",
    "num_added_toks = tokenizer.add_tokens(special_tokens, special_tokens=True)\n",
    "print('[TITLE] token id: ', tokenizer.convert_tokens_to_ids('[TITLE]'))\n",
    "print('[TEXT] token id: ', tokenizer.convert_tokens_to_ids('[TEXT]'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:03:42.599931200Z",
     "start_time": "2024-02-22T12:03:42.259921900Z"
    }
   },
   "id": "8d6cf63c6bcd84ae"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = text.lower()\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_text)\n",
    "\n",
    "\n",
    "class ChunkedTextDataset(Dataset):\n",
    "    def __init__(self, titles, texts, labels, chunk_size=512):\n",
    "        self.inputs = []\n",
    "        self.attention_masks = []\n",
    "        self.labels = []\n",
    "\n",
    "        for title, text, label in zip(titles, texts, labels):\n",
    "            combined_text = '[TITLE] ' + title + ' [TEXT] ' + text\n",
    "            tokenized_text = tokenizer(combined_text, max_length=chunk_size, truncation=True,\n",
    "                                       padding='max_length', return_tensors='pt')\n",
    "            self.inputs.append(tokenized_text['input_ids'])\n",
    "            self.attention_masks.append(tokenized_text['attention_mask'])\n",
    "            self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.inputs[idx].squeeze(),\n",
    "            'attention_mask': self.attention_masks[idx].squeeze(),\n",
    "            'labels': torch.tensor(self.labels[idx])\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:03:42.608373700Z",
     "start_time": "2024-02-22T12:03:42.604400600Z"
    }
   },
   "id": "b7df017fbda9bbfb"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def load_and_prepare_data(split, seed=42, dataset_percentage=1):\n",
    "    if split == \"train\":\n",
    "        reduced_dataset = full_dataset['train'].shuffle(seed=seed).select(\n",
    "            range(int(len(full_dataset['train']) * dataset_percentage)))\n",
    "    else:\n",
    "        reduced_dataset = full_dataset[split]\n",
    "    reduced_texts = tqdm([remove_stopwords(text) for text in reduced_dataset[\"text\"]], desc=f'Cleaning {split} texts')\n",
    "    reduced_labels = reduced_dataset[\"label\"]\n",
    "    reduced_titles = reduced_dataset[\"title\"]\n",
    "    return reduced_titles, reduced_texts, reduced_labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:03:42.617810900Z",
     "start_time": "2024-02-22T12:03:42.610360400Z"
    }
   },
   "id": "4d6d8474f30e6955"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning train texts:   0%|                                                                                                                                   | 0/24353 [00:00<?, ?it/s]\n",
      "Cleaning validation texts:   0%|                                                                                                                               | 0/8117 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "Cleaning train texts: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉| 24352/24353 [01:31<00:00, 266.56it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning validation texts:   0%|                                                                                                                   | 1/8117 [01:10<158:31:19, 70.32s/it]\u001B[A\n",
      "Cleaning validation texts:   0%|▌                                                                                                                   | 40/8117 [01:10<2:47:14,  1.24s/it]\u001B[A\n",
      "Cleaning validation texts:   1%|█▏                                                                                                                  | 87/8117 [01:10<1:01:57,  2.16it/s]\u001B[A\n",
      "Cleaning validation texts:   2%|█▊                                                                                                                   | 130/8117 [01:10<33:59,  3.92it/s]\u001B[A\n",
      "Cleaning validation texts:   2%|██▌                                                                                                                  | 177/8117 [01:10<19:56,  6.63it/s]\u001B[A\n",
      "Cleaning validation texts:   3%|███▏                                                                                                                 | 221/8117 [01:10<12:54, 10.20it/s]\u001B[A\n",
      "Cleaning validation texts:   3%|███▊                                                                                                                 | 266/8117 [01:10<08:32, 15.31it/s]\u001B[A\n",
      "Cleaning validation texts:   4%|████▍                                                                                                                | 308/8117 [01:11<05:56, 21.92it/s]\u001B[A\n",
      "Cleaning validation texts:   4%|█████                                                                                                                | 350/8117 [01:11<04:11, 30.92it/s]\u001B[A\n",
      "Cleaning validation texts:   5%|█████▊                                                                                                               | 400/8117 [01:11<02:49, 45.65it/s]\u001B[A\n",
      "Cleaning validation texts:   5%|██████▍                                                                                                              | 443/8117 [01:11<02:03, 62.02it/s]\u001B[A\n",
      "Cleaning validation texts:   6%|███████                                                                                                              | 493/8117 [01:11<01:27, 87.26it/s]\u001B[A\n",
      "Cleaning validation texts:   7%|███████▋                                                                                                            | 538/8117 [01:11<01:06, 114.37it/s]\u001B[A\n",
      "Cleaning validation texts:   7%|████████▎                                                                                                           | 582/8117 [01:11<00:51, 145.22it/s]\u001B[A\n",
      "Cleaning validation texts:   8%|█████████                                                                                                           | 630/8117 [01:11<00:40, 185.81it/s]\u001B[A\n",
      "Cleaning validation texts:   8%|█████████▋                                                                                                          | 675/8117 [01:11<00:33, 220.36it/s]\u001B[A\n",
      "Cleaning validation texts:   9%|██████████▎                                                                                                         | 724/8117 [01:12<00:27, 266.28it/s]\u001B[A\n",
      "Cleaning validation texts:   9%|███████████                                                                                                         | 771/8117 [01:12<00:24, 305.82it/s]\u001B[A\n",
      "Cleaning validation texts:  10%|███████████▋                                                                                                        | 817/8117 [01:12<00:21, 334.03it/s]\u001B[A\n",
      "Cleaning validation texts:  11%|████████████▎                                                                                                       | 865/8117 [01:12<00:19, 368.38it/s]\u001B[A\n",
      "Cleaning validation texts:  11%|█████████████                                                                                                       | 911/8117 [01:12<00:19, 372.15it/s]\u001B[A\n",
      "Cleaning validation texts:  12%|█████████████▋                                                                                                      | 955/8117 [01:12<00:18, 389.22it/s]\u001B[A\n",
      "Cleaning validation texts:  12%|██████████████▎                                                                                                     | 999/8117 [01:12<00:17, 396.79it/s]\u001B[A\n",
      "Cleaning validation texts:  13%|██████████████▊                                                                                                    | 1042/8117 [01:12<00:17, 394.14it/s]\u001B[A\n",
      "Cleaning validation texts:  13%|███████████████▍                                                                                                   | 1093/8117 [01:12<00:16, 424.70it/s]\u001B[A\n",
      "Cleaning validation texts:  14%|████████████████                                                                                                   | 1138/8117 [01:12<00:16, 412.76it/s]\u001B[A\n",
      "Cleaning validation texts:  15%|████████████████▊                                                                                                  | 1191/8117 [01:13<00:15, 443.30it/s]\u001B[A\n",
      "Cleaning validation texts:  15%|█████████████████▌                                                                                                 | 1243/8117 [01:13<00:14, 463.66it/s]\u001B[A\n",
      "Cleaning validation texts:  16%|██████████████████▍                                                                                                | 1298/8117 [01:13<00:13, 487.35it/s]\u001B[A\n",
      "Cleaning validation texts:  17%|███████████████████▏                                                                                               | 1354/8117 [01:13<00:13, 507.95it/s]\u001B[A\n",
      "Cleaning validation texts:  17%|███████████████████▉                                                                                               | 1406/8117 [01:13<00:13, 503.50it/s]\u001B[A\n",
      "Cleaning validation texts:  18%|████████████████████▋                                                                                              | 1459/8117 [01:13<00:13, 508.90it/s]\u001B[A\n",
      "Cleaning validation texts:  19%|█████████████████████▍                                                                                             | 1511/8117 [01:13<00:13, 500.15it/s]\u001B[A\n",
      "Cleaning validation texts:  19%|██████████████████████▏                                                                                            | 1569/8117 [01:13<00:12, 522.19it/s]\u001B[A\n",
      "Cleaning validation texts:  20%|██████████████████████▉                                                                                            | 1623/8117 [01:13<00:12, 526.24it/s]\u001B[A\n",
      "Cleaning validation texts:  21%|███████████████████████▊                                                                                           | 1678/8117 [01:13<00:12, 532.92it/s]\u001B[A\n",
      "Cleaning validation texts:  21%|████████████████████████▌                                                                                          | 1732/8117 [01:14<00:11, 533.98it/s]\u001B[A\n",
      "Cleaning validation texts:  22%|█████████████████████████▎                                                                                         | 1786/8117 [01:14<00:11, 533.85it/s]\u001B[A\n",
      "Cleaning validation texts:  23%|██████████████████████████                                                                                         | 1841/8117 [01:14<00:11, 535.35it/s]\u001B[A\n",
      "Cleaning validation texts:  23%|██████████████████████████▉                                                                                        | 1900/8117 [01:14<00:11, 549.15it/s]\u001B[A\n",
      "Cleaning validation texts:  24%|███████████████████████████▋                                                                                       | 1955/8117 [01:14<00:11, 531.08it/s]\u001B[A\n",
      "Cleaning validation texts:  25%|████████████████████████████▍                                                                                      | 2009/8117 [01:14<00:12, 504.46it/s]\u001B[A\n",
      "Cleaning validation texts:  25%|█████████████████████████████▏                                                                                     | 2060/8117 [01:14<00:12, 478.47it/s]\u001B[A\n",
      "Cleaning validation texts:  26%|█████████████████████████████▉                                                                                     | 2113/8117 [01:14<00:12, 490.76it/s]\u001B[A\n",
      "Cleaning validation texts:  27%|██████████████████████████████▋                                                                                    | 2163/8117 [01:14<00:13, 450.98it/s]\u001B[A\n",
      "Cleaning validation texts:  27%|███████████████████████████████▎                                                                                   | 2209/8117 [01:15<00:13, 444.05it/s]\u001B[A\n",
      "Cleaning validation texts:  28%|████████████████████████████████                                                                                   | 2260/8117 [01:15<00:12, 461.03it/s]\u001B[A\n",
      "Cleaning validation texts:  28%|████████████████████████████████▋                                                                                  | 2307/8117 [01:15<00:12, 455.71it/s]\u001B[A\n",
      "Cleaning validation texts:  29%|█████████████████████████████████▍                                                                                 | 2356/8117 [01:15<00:12, 461.45it/s]\u001B[A\n",
      "Cleaning validation texts:  30%|██████████████████████████████████                                                                                 | 2403/8117 [01:15<00:13, 429.64it/s]\u001B[A\n",
      "Cleaning validation texts:  30%|██████████████████████████████████▊                                                                                | 2457/8117 [01:15<00:12, 457.71it/s]\u001B[A\n",
      "Cleaning validation texts:  31%|███████████████████████████████████▌                                                                               | 2508/8117 [01:15<00:11, 469.73it/s]\u001B[A\n",
      "Cleaning validation texts:  31%|████████████████████████████████████▏                                                                              | 2556/8117 [01:15<00:12, 460.95it/s]\u001B[A\n",
      "Cleaning validation texts:  32%|████████████████████████████████████▉                                                                              | 2603/8117 [01:15<00:12, 457.48it/s]\u001B[A\n",
      "Cleaning validation texts:  33%|█████████████████████████████████████▌                                                                             | 2649/8117 [01:16<00:12, 424.05it/s]\u001B[A\n",
      "Cleaning validation texts:  33%|██████████████████████████████████████▏                                                                            | 2695/8117 [01:16<00:12, 428.11it/s]\u001B[A\n",
      "Cleaning validation texts:  34%|██████████████████████████████████████▊                                                                            | 2742/8117 [01:16<00:12, 436.64it/s]\u001B[A\n",
      "Cleaning validation texts:  34%|███████████████████████████████████████▍                                                                           | 2786/8117 [01:16<00:13, 406.30it/s]\u001B[A\n",
      "Cleaning validation texts:  35%|████████████████████████████████████████▏                                                                          | 2835/8117 [01:16<00:12, 426.82it/s]\u001B[A\n",
      "Cleaning validation texts:  35%|████████████████████████████████████████▊                                                                          | 2879/8117 [01:16<00:14, 369.84it/s]\u001B[A\n",
      "Cleaning validation texts:  36%|█████████████████████████████████████████▎                                                                         | 2918/8117 [01:16<00:14, 355.53it/s]\u001B[A\n",
      "Cleaning validation texts:  37%|██████████████████████████████████████████                                                                         | 2973/8117 [01:16<00:12, 404.42it/s]\u001B[A\n",
      "Cleaning validation texts:  37%|██████████████████████████████████████████▋                                                                        | 3017/8117 [01:16<00:12, 413.38it/s]\u001B[A\n",
      "Cleaning validation texts:  38%|███████████████████████████████████████████▍                                                                       | 3063/8117 [01:17<00:11, 424.96it/s]\u001B[A\n",
      "Cleaning validation texts:  38%|████████████████████████████████████████████                                                                       | 3114/8117 [01:17<00:11, 448.24it/s]\u001B[A\n",
      "Cleaning validation texts:  39%|████████████████████████████████████████████▉                                                                      | 3172/8117 [01:17<00:10, 485.86it/s]\u001B[A\n",
      "Cleaning validation texts:  40%|█████████████████████████████████████████████▉                                                                     | 3239/8117 [01:17<00:09, 537.91it/s]\u001B[A\n",
      "Cleaning validation texts:  41%|██████████████████████████████████████████████▋                                                                    | 3294/8117 [01:17<00:08, 537.89it/s]\u001B[A\n",
      "Cleaning validation texts:  41%|███████████████████████████████████████████████▍                                                                   | 3349/8117 [01:17<00:09, 517.17it/s]\u001B[A\n",
      "Cleaning validation texts:  42%|████████████████████████████████████████████████▏                                                                  | 3403/8117 [01:17<00:09, 520.23it/s]\u001B[A\n",
      "Cleaning validation texts:  43%|█████████████████████████████████████████████████                                                                  | 3460/8117 [01:17<00:08, 534.28it/s]\u001B[A\n",
      "Cleaning validation texts:  43%|█████████████████████████████████████████████████▊                                                                 | 3514/8117 [01:17<00:08, 520.23it/s]\u001B[A\n",
      "Cleaning validation texts:  44%|██████████████████████████████████████████████████▌                                                                | 3568/8117 [01:18<00:08, 518.12it/s]\u001B[A\n",
      "Cleaning validation texts:  45%|███████████████████████████████████████████████████▍                                                               | 3632/8117 [01:18<00:08, 550.48it/s]\u001B[A\n",
      "Cleaning validation texts:  45%|████████████████████████████████████████████████████▎                                                              | 3688/8117 [01:18<00:08, 525.76it/s]\u001B[A\n",
      "Cleaning validation texts:  46%|█████████████████████████████████████████████████████                                                              | 3741/8117 [01:18<00:08, 508.53it/s]\u001B[A\n",
      "Cleaning validation texts:  47%|█████████████████████████████████████████████████████▋                                                             | 3793/8117 [01:18<00:08, 510.54it/s]\u001B[A\n",
      "Cleaning validation texts:  47%|██████████████████████████████████████████████████████▍                                                            | 3845/8117 [01:18<00:09, 465.81it/s]\u001B[A\n",
      "Cleaning validation texts:  48%|███████████████████████████████████████████████████████▏                                                           | 3893/8117 [01:18<00:09, 464.94it/s]\u001B[A\n",
      "Cleaning validation texts:  49%|███████████████████████████████████████████████████████▊                                                           | 3941/8117 [01:18<00:09, 433.46it/s]\u001B[A\n",
      "Cleaning validation texts:  49%|████████████████████████████████████████████████████████▍                                                          | 3986/8117 [01:18<00:09, 419.86it/s]\u001B[A\n",
      "Cleaning validation texts:  50%|█████████████████████████████████████████████████████████▏                                                         | 4033/8117 [01:19<00:09, 429.83it/s]\u001B[A\n",
      "Cleaning validation texts:  50%|█████████████████████████████████████████████████████████▊                                                         | 4077/8117 [01:19<00:09, 425.61it/s]\u001B[A\n",
      "Cleaning validation texts:  51%|██████████████████████████████████████████████████████████▍                                                        | 4124/8117 [01:19<00:09, 435.91it/s]\u001B[A\n",
      "Cleaning validation texts:  51%|███████████████████████████████████████████████████████████                                                        | 4173/8117 [01:19<00:08, 451.02it/s]\u001B[A\n",
      "Cleaning validation texts:  52%|███████████████████████████████████████████████████████████▊                                                       | 4219/8117 [01:19<00:09, 404.78it/s]\u001B[A\n",
      "Cleaning validation texts:  53%|████████████████████████████████████████████████████████████▍                                                      | 4265/8117 [01:19<00:09, 418.08it/s]\u001B[A\n",
      "Cleaning validation texts:  53%|█████████████████████████████████████████████████████████████▏                                                     | 4316/8117 [01:19<00:08, 440.64it/s]\u001B[A\n",
      "Cleaning validation texts:  54%|█████████████████████████████████████████████████████████████▊                                                     | 4361/8117 [01:19<00:09, 414.51it/s]\u001B[A\n",
      "Cleaning validation texts:  54%|██████████████████████████████████████████████████████████████▍                                                    | 4404/8117 [01:19<00:09, 395.51it/s]\u001B[A\n",
      "Cleaning validation texts:  55%|██████████████████████████████████████████████████████████████▉                                                    | 4445/8117 [01:20<00:09, 388.35it/s]\u001B[A\n",
      "Cleaning validation texts:  55%|███████████████████████████████████████████████████████████████▌                                                   | 4488/8117 [01:20<00:09, 399.24it/s]\u001B[A\n",
      "Cleaning validation texts:  56%|████████████████████████████████████████████████████████████████▏                                                  | 4531/8117 [01:20<00:08, 407.57it/s]\u001B[A\n",
      "Cleaning validation texts:  56%|████████████████████████████████████████████████████████████████▊                                                  | 4573/8117 [01:20<00:08, 407.28it/s]\u001B[A\n",
      "Cleaning validation texts:  57%|█████████████████████████████████████████████████████████████████▍                                                 | 4616/8117 [01:20<00:08, 412.64it/s]\u001B[A\n",
      "Cleaning validation texts:  57%|█████████████████████████████████████████████████████████████████▉                                                 | 4658/8117 [01:20<00:08, 405.43it/s]\u001B[A\n",
      "Cleaning validation texts:  58%|██████████████████████████████████████████████████████████████████▊                                                | 4712/8117 [01:20<00:07, 443.30it/s]\u001B[A\n",
      "Cleaning validation texts:  59%|███████████████████████████████████████████████████████████████████▌                                               | 4771/8117 [01:20<00:06, 485.99it/s]\u001B[A\n",
      "Cleaning validation texts:  59%|████████████████████████████████████████████████████████████████████▎                                              | 4820/8117 [01:20<00:06, 476.76it/s]\u001B[A\n",
      "Cleaning validation texts:  60%|████████████████████████████████████████████████████████████████████▉                                              | 4868/8117 [01:21<00:07, 448.46it/s]\u001B[A\n",
      "Cleaning validation texts:  61%|█████████████████████████████████████████████████████████████████████▌                                             | 4914/8117 [01:21<00:07, 422.47it/s]\u001B[A\n",
      "Cleaning validation texts:  61%|██████████████████████████████████████████████████████████████████████▏                                            | 4957/8117 [01:21<00:07, 418.14it/s]\u001B[A\n",
      "Cleaning validation texts:  62%|██████████████████████████████████████████████████████████████████████▊                                            | 5000/8117 [01:21<00:07, 416.22it/s]\u001B[A\n",
      "Cleaning validation texts:  62%|███████████████████████████████████████████████████████████████████████▍                                           | 5042/8117 [01:21<00:07, 410.53it/s]\u001B[A\n",
      "Cleaning validation texts:  63%|████████████████████████████████████████████████████████████████████████                                           | 5086/8117 [01:21<00:07, 418.73it/s]\u001B[A\n",
      "Cleaning validation texts:  63%|████████████████████████████████████████████████████████████████████████▋                                          | 5129/8117 [01:21<00:07, 415.00it/s]\u001B[A\n",
      "Cleaning validation texts:  64%|█████████████████████████████████████████████████████████████████████████▎                                         | 5171/8117 [01:21<00:07, 394.90it/s]\u001B[A\n",
      "Cleaning validation texts:  64%|█████████████████████████████████████████████████████████████████████████▊                                         | 5213/8117 [01:21<00:07, 401.70it/s]\u001B[A\n",
      "Cleaning validation texts:  65%|██████████████████████████████████████████████████████████████████████████▍                                        | 5254/8117 [01:22<00:07, 370.94it/s]\u001B[A\n",
      "Cleaning validation texts:  65%|███████████████████████████████████████████████████████████████████████████▏                                       | 5306/8117 [01:22<00:06, 410.73it/s]\u001B[A\n",
      "Cleaning validation texts:  66%|███████████████████████████████████████████████████████████████████████████▊                                       | 5348/8117 [01:22<00:07, 392.81it/s]\u001B[A\n",
      "Cleaning validation texts:  66%|████████████████████████████████████████████████████████████████████████████▍                                      | 5396/8117 [01:22<00:06, 415.15it/s]\u001B[A\n",
      "Cleaning validation texts:  67%|█████████████████████████████████████████████████████████████████████████████                                      | 5443/8117 [01:22<00:06, 430.09it/s]\u001B[A\n",
      "Cleaning validation texts:  68%|█████████████████████████████████████████████████████████████████████████████▉                                     | 5503/8117 [01:22<00:05, 477.63it/s]\u001B[A\n",
      "Cleaning validation texts:  68%|██████████████████████████████████████████████████████████████████████████████▋                                    | 5552/8117 [01:22<00:05, 480.18it/s]\u001B[A\n",
      "Cleaning validation texts:  69%|███████████████████████████████████████████████████████████████████████████████▌                                   | 5618/8117 [01:22<00:04, 531.44it/s]\u001B[A\n",
      "Cleaning validation texts:  70%|████████████████████████████████████████████████████████████████████████████████▍                                  | 5675/8117 [01:22<00:04, 542.59it/s]\u001B[A\n",
      "Cleaning validation texts:  71%|█████████████████████████████████████████████████████████████████████████████████▏                                 | 5730/8117 [01:22<00:04, 483.22it/s]\u001B[A\n",
      "Cleaning validation texts:  71%|█████████████████████████████████████████████████████████████████████████████████▉                                 | 5781/8117 [01:23<00:04, 486.72it/s]\u001B[A\n",
      "Cleaning validation texts:  72%|██████████████████████████████████████████████████████████████████████████████████▋                                | 5833/8117 [01:23<00:04, 494.82it/s]\u001B[A\n",
      "Cleaning validation texts:  73%|███████████████████████████████████████████████████████████████████████████████████▍                               | 5887/8117 [01:23<00:04, 505.80it/s]\u001B[A\n",
      "Cleaning validation texts:  73%|████████████████████████████████████████████████████████████████████████████████████▎                              | 5952/8117 [01:23<00:03, 545.59it/s]\u001B[A\n",
      "Cleaning validation texts:  74%|█████████████████████████████████████████████████████████████████████████████████████                              | 6008/8117 [01:23<00:03, 540.67it/s]\u001B[A\n",
      "Cleaning validation texts:  75%|█████████████████████████████████████████████████████████████████████████████████████▉                             | 6067/8117 [01:23<00:03, 553.52it/s]\u001B[A\n",
      "Cleaning validation texts:  76%|██████████████████████████████████████████████████████████████████████████████████████▊                            | 6129/8117 [01:23<00:03, 570.81it/s]\u001B[A\n",
      "Cleaning validation texts:  76%|███████████████████████████████████████████████████████████████████████████████████████▋                           | 6187/8117 [01:23<00:03, 559.45it/s]\u001B[A\n",
      "Cleaning validation texts:  77%|████████████████████████████████████████████████████████████████████████████████████████▌                          | 6248/8117 [01:23<00:03, 571.08it/s]\u001B[A\n",
      "Cleaning validation texts:  78%|█████████████████████████████████████████████████████████████████████████████████████████▍                         | 6313/8117 [01:24<00:03, 592.22it/s]\u001B[A\n",
      "Cleaning validation texts:  79%|██████████████████████████████████████████████████████████████████████████████████████████▎                        | 6373/8117 [01:24<00:02, 586.20it/s]\u001B[A\n",
      "Cleaning validation texts:  79%|███████████████████████████████████████████████████████████████████████████████████████████▏                       | 6432/8117 [01:24<00:02, 569.69it/s]\u001B[A\n",
      "Cleaning validation texts:  80%|███████████████████████████████████████████████████████████████████████████████████████████▉                       | 6490/8117 [01:24<00:02, 542.86it/s]\u001B[A\n",
      "Cleaning validation texts:  81%|████████████████████████████████████████████████████████████████████████████████████████████▋                      | 6545/8117 [01:24<00:02, 537.99it/s]\u001B[A\n",
      "Cleaning validation texts:  81%|█████████████████████████████████████████████████████████████████████████████████████████████▌                     | 6600/8117 [01:24<00:02, 537.83it/s]\u001B[A\n",
      "Cleaning validation texts:  82%|██████████████████████████████████████████████████████████████████████████████████████████████▎                    | 6656/8117 [01:24<00:02, 542.76it/s]\u001B[A\n",
      "Cleaning validation texts:  83%|███████████████████████████████████████████████████████████████████████████████████████████████                    | 6711/8117 [01:24<00:02, 536.31it/s]\u001B[A\n",
      "Cleaning validation texts:  83%|███████████████████████████████████████████████████████████████████████████████████████████████▊                   | 6765/8117 [01:24<00:02, 533.02it/s]\u001B[A\n",
      "Cleaning validation texts:  84%|████████████████████████████████████████████████████████████████████████████████████████████████▌                  | 6819/8117 [01:24<00:02, 530.39it/s]\u001B[A\n",
      "Cleaning validation texts:  85%|█████████████████████████████████████████████████████████████████████████████████████████████████▌                 | 6886/8117 [01:25<00:02, 570.59it/s]\u001B[A\n",
      "Cleaning validation texts:  86%|██████████████████████████████████████████████████████████████████████████████████████████████████▍                | 6949/8117 [01:25<00:01, 587.93it/s]\u001B[A\n",
      "Cleaning validation texts:  86%|███████████████████████████████████████████████████████████████████████████████████████████████████▎               | 7008/8117 [01:25<00:02, 552.35it/s]\u001B[A\n",
      "Cleaning validation texts:  87%|████████████████████████████████████████████████████████████████████████████████████████████████████               | 7064/8117 [01:25<00:02, 511.42it/s]\u001B[A\n",
      "Cleaning validation texts:  88%|████████████████████████████████████████████████████████████████████████████████████████████████████▊              | 7116/8117 [01:25<00:02, 468.38it/s]\u001B[A\n",
      "Cleaning validation texts:  88%|█████████████████████████████████████████████████████████████████████████████████████████████████████▌             | 7170/8117 [01:25<00:01, 486.11it/s]\u001B[A\n",
      "Cleaning validation texts:  89%|██████████████████████████████████████████████████████████████████████████████████████████████████████▎            | 7220/8117 [01:25<00:01, 453.61it/s]\u001B[A\n",
      "Cleaning validation texts:  90%|██████████████████████████████████████████████████████████████████████████████████████████████████████▉            | 7267/8117 [01:25<00:01, 442.19it/s]\u001B[A\n",
      "Cleaning validation texts:  90%|███████████████████████████████████████████████████████████████████████████████████████████████████████▋           | 7315/8117 [01:25<00:01, 450.65it/s]\u001B[A\n",
      "Cleaning validation texts:  91%|████████████████████████████████████████████████████████████████████████████████████████████████████████▎          | 7361/8117 [01:26<00:01, 414.96it/s]\u001B[A\n",
      "Cleaning validation texts:  91%|████████████████████████████████████████████████████████████████████████████████████████████████████████▉          | 7406/8117 [01:26<00:01, 421.42it/s]\u001B[A\n",
      "Cleaning validation texts:  92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▌         | 7449/8117 [01:26<00:01, 420.76it/s]\u001B[A\n",
      "Cleaning validation texts:  92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▏        | 7492/8117 [01:26<00:01, 421.07it/s]\u001B[A\n",
      "Cleaning validation texts:  93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▊        | 7541/8117 [01:26<00:01, 438.06it/s]\u001B[A\n",
      "Cleaning validation texts:  93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▍       | 7586/8117 [01:26<00:01, 425.38it/s]\u001B[A\n",
      "Cleaning validation texts:  94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▏      | 7640/8117 [01:26<00:01, 457.32it/s]\u001B[A\n",
      "Cleaning validation texts:  95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▉      | 7687/8117 [01:26<00:00, 435.13it/s]\u001B[A\n",
      "Cleaning validation texts:  95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌     | 7731/8117 [01:26<00:00, 431.54it/s]\u001B[A\n",
      "Cleaning validation texts:  96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▏    | 7775/8117 [01:27<00:00, 432.04it/s]\u001B[A\n",
      "Cleaning validation texts:  96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▊    | 7823/8117 [01:27<00:00, 445.00it/s]\u001B[A\n",
      "Cleaning validation texts:  97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▍   | 7868/8117 [01:27<00:00, 423.05it/s]\u001B[A\n",
      "Cleaning validation texts:  97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████   | 7911/8117 [01:27<00:00, 411.22it/s]\u001B[A\n",
      "Cleaning validation texts:  98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊  | 7959/8117 [01:27<00:00, 428.34it/s]\u001B[A\n",
      "Cleaning validation texts:  99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍ | 8003/8117 [01:27<00:00, 429.13it/s]\u001B[A\n",
      "Cleaning validation texts:  99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏| 8057/8117 [01:27<00:00, 455.39it/s]\u001B[A\n",
      "Cleaning validation texts: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉| 8116/8117 [01:27<00:00, 92.38it/s]\u001B[A\n",
      "\n",
      "\n",
      "Cleaning test texts:   0%|                                                                                                                         | 1/8117 [01:06<150:47:15, 66.88s/it]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:   1%|▋                                                                                                                         | 47/8117 [01:06<2:15:08,  1.00s/it]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:   1%|█▍                                                                                                                          | 93/8117 [01:07<56:01,  2.39it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:   2%|██                                                                                                                         | 134/8117 [01:07<32:06,  4.14it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:   2%|██▊                                                                                                                        | 185/8117 [01:07<18:15,  7.24it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:   3%|███▍                                                                                                                       | 228/8117 [01:07<12:04, 10.89it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:   3%|████                                                                                                                       | 271/8117 [01:07<08:09, 16.01it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:   4%|████▋                                                                                                                      | 313/8117 [01:07<05:40, 22.93it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:   4%|█████▍                                                                                                                     | 355/8117 [01:07<03:59, 32.36it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:   5%|██████▎                                                                                                                    | 416/8117 [01:07<02:29, 51.38it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:   6%|███████                                                                                                                    | 463/8117 [01:07<01:49, 69.94it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:   6%|███████▋                                                                                                                   | 510/8117 [01:08<01:20, 93.95it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:   7%|████████▎                                                                                                                 | 556/8117 [01:08<01:02, 120.34it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:   7%|█████████                                                                                                                 | 602/8117 [01:08<00:48, 154.15it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:   8%|█████████▊                                                                                                                | 650/8117 [01:08<00:38, 193.80it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:   9%|██████████▍                                                                                                               | 695/8117 [01:08<00:33, 224.61it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:   9%|███████████▏                                                                                                              | 746/8117 [01:08<00:26, 273.04it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  10%|███████████▉                                                                                                              | 791/8117 [01:08<00:24, 296.12it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  10%|████████████▋                                                                                                             | 846/8117 [01:08<00:20, 349.47it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  11%|█████████████▍                                                                                                            | 893/8117 [01:08<00:19, 363.02it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  12%|██████████████                                                                                                            | 938/8117 [01:09<00:19, 366.33it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  12%|██████████████▋                                                                                                           | 981/8117 [01:09<00:18, 380.71it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  13%|███████████████▎                                                                                                         | 1024/8117 [01:09<00:18, 386.79it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  13%|████████████████                                                                                                         | 1081/8117 [01:09<00:16, 433.78it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  14%|████████████████▊                                                                                                        | 1127/8117 [01:09<00:16, 414.16it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  14%|█████████████████▍                                                                                                       | 1171/8117 [01:09<00:16, 413.03it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  15%|██████████████████▏                                                                                                      | 1224/8117 [01:09<00:15, 442.63it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  16%|██████████████████▉                                                                                                      | 1270/8117 [01:09<00:16, 413.29it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  16%|███████████████████▋                                                                                                     | 1317/8117 [01:09<00:15, 428.59it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  17%|████████████████████▎                                                                                                    | 1361/8117 [01:10<00:16, 418.38it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  17%|█████████████████████                                                                                                    | 1411/8117 [01:10<00:15, 438.41it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  18%|█████████████████████▋                                                                                                   | 1458/8117 [01:10<00:14, 446.76it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  19%|██████████████████████▍                                                                                                  | 1504/8117 [01:10<00:16, 409.02it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  19%|███████████████████████▏                                                                                                 | 1552/8117 [01:10<00:15, 426.88it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  20%|███████████████████████▊                                                                                                 | 1596/8117 [01:10<00:15, 412.45it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  20%|████████████████████████▍                                                                                                | 1638/8117 [01:10<00:16, 400.48it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  21%|█████████████████████████                                                                                                | 1682/8117 [01:10<00:15, 408.72it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  21%|█████████████████████████▋                                                                                               | 1724/8117 [01:10<00:16, 387.19it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  22%|██████████████████████████▌                                                                                              | 1781/8117 [01:11<00:14, 434.49it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  22%|███████████████████████████▏                                                                                             | 1826/8117 [01:11<00:14, 427.48it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  23%|███████████████████████████▉                                                                                             | 1870/8117 [01:11<00:14, 421.81it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  24%|████████████████████████████▌                                                                                            | 1914/8117 [01:11<00:14, 425.36it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  24%|█████████████████████████████▏                                                                                           | 1957/8117 [01:11<00:15, 391.89it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  25%|██████████████████████████████                                                                                           | 2019/8117 [01:11<00:13, 450.49it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  26%|██████████████████████████████▉                                                                                          | 2077/8117 [01:11<00:12, 486.06it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  26%|███████████████████████████████▊                                                                                         | 2138/8117 [01:11<00:11, 516.54it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  27%|████████████████████████████████▋                                                                                        | 2191/8117 [01:11<00:12, 491.14it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  28%|█████████████████████████████████▍                                                                                       | 2246/8117 [01:12<00:11, 507.42it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  28%|██████████████████████████████████▎                                                                                      | 2298/8117 [01:12<00:11, 505.37it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  29%|███████████████████████████████████                                                                                      | 2356/8117 [01:12<00:10, 526.09it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  30%|████████████████████████████████████                                                                                     | 2418/8117 [01:12<00:10, 552.18it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  30%|████████████████████████████████████▉                                                                                    | 2474/8117 [01:12<00:10, 536.79it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  31%|█████████████████████████████████████▋                                                                                   | 2531/8117 [01:12<00:10, 543.63it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  32%|██████████████████████████████████████▌                                                                                  | 2586/8117 [01:12<00:10, 542.95it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  33%|███████████████████████████████████████▎                                                                                 | 2641/8117 [01:12<00:16, 337.01it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  33%|████████████████████████████████████████▎                                                                                | 2703/8117 [01:13<00:13, 394.82it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  34%|█████████████████████████████████████████                                                                                | 2757/8117 [01:13<00:12, 427.10it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  35%|█████████████████████████████████████████▉                                                                               | 2812/8117 [01:13<00:11, 456.87it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  35%|██████████████████████████████████████████▊                                                                              | 2870/8117 [01:13<00:10, 487.80it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  36%|███████████████████████████████████████████▌                                                                             | 2925/8117 [01:13<00:10, 503.79it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  37%|████████████████████████████████████████████▍                                                                            | 2982/8117 [01:13<00:09, 520.44it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  37%|█████████████████████████████████████████████▎                                                                           | 3037/8117 [01:13<00:09, 514.03it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  38%|██████████████████████████████████████████████                                                                           | 3091/8117 [01:13<00:10, 502.56it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  39%|██████████████████████████████████████████████▊                                                                          | 3143/8117 [01:13<00:10, 496.43it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  39%|███████████████████████████████████████████████▋                                                                         | 3197/8117 [01:13<00:09, 506.72it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  40%|████████████████████████████████████████████████▍                                                                        | 3250/8117 [01:14<00:09, 513.25it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  41%|█████████████████████████████████████████████████▏                                                                       | 3302/8117 [01:14<00:10, 453.51it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  41%|█████████████████████████████████████████████████▉                                                                       | 3349/8117 [01:14<00:10, 448.51it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  42%|██████████████████████████████████████████████████▋                                                                      | 3401/8117 [01:14<00:10, 467.51it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  42%|███████████████████████████████████████████████████▍                                                                     | 3449/8117 [01:14<00:10, 436.41it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  43%|████████████████████████████████████████████████████                                                                     | 3495/8117 [01:14<00:10, 440.48it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  44%|████████████████████████████████████████████████████▊                                                                    | 3540/8117 [01:14<00:10, 423.59it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  44%|█████████████████████████████████████████████████████▌                                                                   | 3593/8117 [01:14<00:10, 450.96it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  45%|██████████████████████████████████████████████████████▏                                                                  | 3639/8117 [01:15<00:10, 409.47it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  45%|██████████████████████████████████████████████████████▉                                                                  | 3682/8117 [01:15<00:10, 412.77it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  46%|███████████████████████████████████████████████████████▌                                                                 | 3725/8117 [01:15<00:10, 401.90it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  47%|████████████████████████████████████████████████████████▍                                                                | 3789/8117 [01:15<00:09, 465.05it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  47%|█████████████████████████████████████████████████████████▏                                                               | 3840/8117 [01:15<00:09, 474.75it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  48%|██████████████████████████████████████████████████████████▏                                                              | 3901/8117 [01:15<00:08, 509.86it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  49%|███████████████████████████████████████████████████████████                                                              | 3962/8117 [01:15<00:07, 538.11it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  50%|███████████████████████████████████████████████████████████▉                                                             | 4020/8117 [01:15<00:07, 549.32it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  50%|████████████████████████████████████████████████████████████▊                                                            | 4076/8117 [01:15<00:07, 546.90it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  51%|█████████████████████████████████████████████████████████████▋                                                           | 4140/8117 [01:15<00:06, 573.64it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  52%|██████████████████████████████████████████████████████████████▌                                                          | 4198/8117 [01:16<00:07, 554.03it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  52%|███████████████████████████████████████████████████████████████▍                                                         | 4254/8117 [01:16<00:07, 547.36it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  53%|████████████████████████████████████████████████████████████████▎                                                        | 4316/8117 [01:16<00:06, 567.96it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  54%|█████████████████████████████████████████████████████████████████▏                                                       | 4374/8117 [01:16<00:06, 554.58it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  55%|██████████████████████████████████████████████████████████████████                                                       | 4434/8117 [01:16<00:06, 566.62it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  55%|███████████████████████████████████████████████████████████████████                                                      | 4495/8117 [01:16<00:06, 579.02it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  56%|████████████████████████████████████████████████████████████████████                                                     | 4562/8117 [01:16<00:05, 602.06it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  57%|████████████████████████████████████████████████████████████████████▉                                                    | 4623/8117 [01:16<00:05, 595.90it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  58%|█████████████████████████████████████████████████████████████████████▊                                                   | 4683/8117 [01:16<00:05, 584.96it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  58%|██████████████████████████████████████████████████████████████████████▋                                                  | 4742/8117 [01:17<00:05, 577.37it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  59%|███████████████████████████████████████████████████████████████████████▌                                                 | 4800/8117 [01:17<00:05, 559.17it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  60%|████████████████████████████████████████████████████████████████████████▍                                                | 4857/8117 [01:17<00:06, 539.66it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  61%|█████████████████████████████████████████████████████████████████████████▎                                               | 4914/8117 [01:17<00:05, 544.67it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  61%|██████████████████████████████████████████████████████████████████████████                                               | 4972/8117 [01:17<00:05, 553.73it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  62%|██████████████████████████████████████████████████████████████████████████▉                                              | 5030/8117 [01:17<00:05, 559.79it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  63%|███████████████████████████████████████████████████████████████████████████▊                                             | 5087/8117 [01:17<00:06, 501.37it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  63%|████████████████████████████████████████████████████████████████████████████▌                                            | 5139/8117 [01:17<00:06, 471.54it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  64%|█████████████████████████████████████████████████████████████████████████████▎                                           | 5189/8117 [01:17<00:06, 474.72it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  65%|██████████████████████████████████████████████████████████████████████████████                                           | 5238/8117 [01:18<00:06, 477.09it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  65%|██████████████████████████████████████████████████████████████████████████████▊                                          | 5287/8117 [01:18<00:06, 422.11it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  66%|███████████████████████████████████████████████████████████████████████████████▋                                         | 5345/8117 [01:18<00:06, 459.07it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  66%|████████████████████████████████████████████████████████████████████████████████▍                                        | 5393/8117 [01:18<00:06, 452.19it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  67%|█████████████████████████████████████████████████████████████████████████████████                                        | 5440/8117 [01:18<00:06, 404.04it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  68%|█████████████████████████████████████████████████████████████████████████████████▊                                       | 5490/8117 [01:18<00:06, 427.00it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  68%|██████████████████████████████████████████████████████████████████████████████████▌                                      | 5535/8117 [01:18<00:06, 418.30it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  69%|███████████████████████████████████████████████████████████████████████████████████▏                                     | 5580/8117 [01:18<00:05, 425.68it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  69%|███████████████████████████████████████████████████████████████████████████████████▊                                     | 5624/8117 [01:18<00:05, 421.97it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  70%|████████████████████████████████████████████████████████████████████████████████████▌                                    | 5673/8117 [01:19<00:05, 439.06it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  70%|█████████████████████████████████████████████████████████████████████████████████████▏                                   | 5718/8117 [01:19<00:05, 421.90it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  71%|█████████████████████████████████████████████████████████████████████████████████████▉                                   | 5767/8117 [01:19<00:05, 431.98it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  72%|██████████████████████████████████████████████████████████████████████████████████████▋                                  | 5817/8117 [01:19<00:05, 450.96it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  72%|███████████████████████████████████████████████████████████████████████████████████████▍                                 | 5863/8117 [01:19<00:05, 434.93it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  73%|████████████████████████████████████████████████████████████████████████████████████████                                 | 5907/8117 [01:19<00:05, 432.79it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  73%|████████████████████████████████████████████████████████████████████████████████████████▊                                | 5960/8117 [01:19<00:04, 460.25it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  74%|█████████████████████████████████████████████████████████████████████████████████████████▌                               | 6010/8117 [01:19<00:04, 471.51it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  75%|██████████████████████████████████████████████████████████████████████████████████████████▍                              | 6064/8117 [01:19<00:04, 491.08it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  75%|███████████████████████████████████████████████████████████████████████████████████████████▏                             | 6116/8117 [01:19<00:04, 499.02it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  76%|████████████████████████████████████████████████████████████████████████████████████████████▏                            | 6180/8117 [01:20<00:03, 538.06it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  77%|████████████████████████████████████████████████████████████████████████████████████████████▉                            | 6237/8117 [01:20<00:03, 542.87it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  78%|█████████████████████████████████████████████████████████████████████████████████████████████▉                           | 6299/8117 [01:20<00:03, 563.39it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  78%|██████████████████████████████████████████████████████████████████████████████████████████████▊                          | 6357/8117 [01:20<00:03, 563.25it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  79%|███████████████████████████████████████████████████████████████████████████████████████████████▋                         | 6420/8117 [01:20<00:02, 582.65it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  80%|████████████████████████████████████████████████████████████████████████████████████████████████▌                        | 6479/8117 [01:20<00:03, 539.18it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  81%|█████████████████████████████████████████████████████████████████████████████████████████████████▍                       | 6537/8117 [01:20<00:02, 548.56it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  81%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                      | 6594/8117 [01:20<00:02, 553.21it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  82%|███████████████████████████████████████████████████████████████████████████████████████████████████▏                     | 6650/8117 [01:20<00:02, 550.96it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  83%|████████████████████████████████████████████████████████████████████████████████████████████████████                     | 6709/8117 [01:21<00:02, 556.73it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  83%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                    | 6765/8117 [01:21<00:02, 550.61it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  84%|█████████████████████████████████████████████████████████████████████████████████████████████████████▋                   | 6821/8117 [01:21<00:02, 531.88it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  85%|██████████████████████████████████████████████████████████████████████████████████████████████████████▌                  | 6880/8117 [01:21<00:02, 539.95it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  85%|███████████████████████████████████████████████████████████████████████████████████████████████████████▍                 | 6938/8117 [01:21<00:02, 551.40it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  86%|████████████████████████████████████████████████████████████████████████████████████████████████████████▎                | 6994/8117 [01:21<00:02, 551.39it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████                | 7050/8117 [01:21<00:02, 488.60it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▊               | 7101/8117 [01:21<00:02, 485.24it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▋              | 7154/8117 [01:21<00:01, 495.58it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▍             | 7210/8117 [01:22<00:01, 513.27it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▎            | 7265/8117 [01:22<00:01, 523.69it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████            | 7318/8117 [01:22<00:01, 508.93it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████           | 7380/8117 [01:22<00:01, 533.99it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▊          | 7434/8117 [01:22<00:01, 509.76it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▋         | 7491/8117 [01:22<00:01, 525.51it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌        | 7547/8117 [01:22<00:01, 533.90it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 7601/8117 [01:22<00:01, 467.01it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏      | 7656/8117 [01:22<00:00, 487.38it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉      | 7707/8117 [01:23<00:00, 467.31it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋     | 7757/8117 [01:23<00:00, 472.92it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎    | 7806/8117 [01:23<00:00, 462.84it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████    | 7853/8117 [01:23<00:00, 449.51it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊   | 7899/8117 [01:23<00:00, 452.12it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍  | 7945/8117 [01:23<00:00, 438.61it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts:  99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍ | 8008/8117 [01:23<00:00, 488.88it/s]\u001B[A\u001B[A\n",
      "\n",
      "Cleaning test texts: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉| 8116/8117 [01:23<00:00, 96.76it/s]\u001B[A\u001B[A\n"
     ]
    }
   ],
   "source": [
    "# Load dataset splits\n",
    "train_titles, train_texts, train_labels = load_and_prepare_data(\"train\")\n",
    "val_titles, val_texts, val_labels = load_and_prepare_data(\"validation\")\n",
    "test_titles, test_texts, test_labels = load_and_prepare_data(\"test\")\n",
    "\n",
    "train_dataset = ChunkedTextDataset(train_titles, train_texts, train_labels)\n",
    "val_dataset = ChunkedTextDataset(val_titles, val_texts, val_labels)\n",
    "test_dataset = ChunkedTextDataset(test_titles, test_texts, test_labels)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:06:53.961835500Z",
     "start_time": "2024-02-22T12:03:42.619300900Z"
    }
   },
   "id": "6e236df98419a387"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    " data exploration is an important step in any machine learning project. It allows us to understand the data and identify any issues that need to be addressed. In this section, we will explore the `GonzaloA/fake_news` dataset and perform some basic analysis to gain insights into the data.\n",
    " \n",
    " we first visualize the distribution of the labels in the training, validation, and test sets. We then create a word cloud to visualize the most common words in the dataset. We also plot the top 10 most common words in the dataset. Finally, we visualize the top 20 bigrams and trigrams in the dataset, annotated with the counts for each class (fake and real).\n",
    " ."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84b8a63f8b0d6bcb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a word cloud\n",
    "def generate_word_cloud(texts):\n",
    "    combined_text = \" \".join(texts)\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(\n",
    "        combined_text)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Show word cloud\n",
    "generate_word_cloud(train_texts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T12:01:37.537219200Z"
    }
   },
   "id": "958e846a98d81fe8"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def plot_top_words(data, n=10):\n",
    "    counter = Counter(\" \".join(data).split())\n",
    "    most_common = counter.most_common(n)\n",
    "    most_common_words = [word for word, freq in most_common]\n",
    "    frequencies = [freq for word, freq in most_common]\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    sns.barplot(x=most_common_words, y=frequencies)\n",
    "    plt.title('Top 10 most common words')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T11:09:04.428248400Z",
     "start_time": "2024-02-22T11:09:04.427751700Z"
    }
   },
   "id": "25de8dafd486d02b"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def clean_text_for_visualization(text):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.translate(str.maketrans('', '', string.digits))\n",
    "    text = text.translate(str.maketrans('', '', \"“”‘’—\"))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word.isalpha() and word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T11:09:04.428745100Z",
     "start_time": "2024-02-22T11:09:04.428248400Z"
    }
   },
   "id": "1dfd5d603d951c8f"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1080x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cleaned_texts_for_visualization = [clean_text_for_visualization(text) for text in train_texts]\n",
    "plot_top_words(cleaned_texts_for_visualization)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T11:09:31.014753600Z",
     "start_time": "2024-02-22T11:09:04.428248400Z"
    }
   },
   "id": "378654092170a554"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def plot_annotated_ngrams_fixed(texts, labels, n=2, n_terms=20):\n",
    "    vec = CountVectorizer(ngram_range=(n, n)).fit(texts)\n",
    "    bag_of_words = vec.transform(texts)\n",
    "    feature_names = vec.get_feature_names_out()\n",
    "    sum_words = bag_of_words.sum(axis=0)\n",
    "\n",
    "    # Calculate the counts for each class\n",
    "    class_counts = np.zeros((2, len(feature_names)))\n",
    "    for label, row in zip(labels, bag_of_words):\n",
    "        class_counts[label] += row.toarray()[0]\n",
    "\n",
    "    # Aggregate total counts for each n-gram and sort them\n",
    "    total_counts = sum_words.A1\n",
    "    indices = np.argsort(-total_counts)\n",
    "    top_indices = indices[:n_terms]\n",
    "\n",
    "    # Prepare the data for plotting\n",
    "    top_ngrams = feature_names[top_indices]\n",
    "    top_counts = total_counts[top_indices]\n",
    "    top_fake_counts = class_counts[0, top_indices]\n",
    "    top_real_counts = class_counts[1, top_indices]\n",
    "\n",
    "    data = {\n",
    "        'ngram': top_ngrams,\n",
    "        'frequency': top_counts,\n",
    "        'fake_count': top_fake_counts,\n",
    "        'real_count': top_real_counts\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    bars = sns.barplot(x='frequency', y='ngram', hue='ngram', data=df, palette='viridis', legend=False)\n",
    "    plt.title(f'Top {n}-grams in Dataset')\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel(f'{n}-grams')\n",
    "\n",
    "    # Annotate bars with the count of fake and real labels\n",
    "    for i, bar in enumerate(bars.patches):\n",
    "        plt.text(\n",
    "            bar.get_width(),\n",
    "            bar.get_y() + bar.get_height() / 2,\n",
    "            f'Fake: {int(df.iloc[i][\"fake_count\"])}, Real: {int(df.iloc[i][\"real_count\"])}',\n",
    "            va='center'\n",
    "        )\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T11:09:31.014753600Z",
     "start_time": "2024-02-22T11:09:31.003330500Z"
    }
   },
   "id": "5e16564669fb0d89"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_23611/2317921622.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mplot_annotated_ngrams_fixed\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_texts\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_labels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_terms\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m20\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_23611/532259790.py\u001B[0m in \u001B[0;36mplot_annotated_ngrams_fixed\u001B[0;34m(texts, labels, n, n_terms)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mplot_annotated_ngrams_fixed\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtexts\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_terms\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m20\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m     \u001B[0mvec\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mCountVectorizer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mngram_range\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtexts\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m     \u001B[0mbag_of_words\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvec\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtexts\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m     \u001B[0mfeature_names\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvec\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_feature_names_out\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0msum_words\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbag_of_words\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py\u001B[0m in \u001B[0;36mtransform\u001B[0;34m(self, raw_documents)\u001B[0m\n\u001B[1;32m   1432\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1433\u001B[0m         \u001B[0;31m# use the same matrix-building strategy as fit_transform\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1434\u001B[0;31m         \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_count_vocab\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mraw_documents\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfixed_vocab\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1435\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbinary\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1436\u001B[0m             \u001B[0mX\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfill\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py\u001B[0m in \u001B[0;36m_count_vocab\u001B[0;34m(self, raw_documents, fixed_vocab)\u001B[0m\n\u001B[1;32m   1274\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mdoc\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mraw_documents\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1275\u001B[0m             \u001B[0mfeature_counter\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1276\u001B[0;31m             \u001B[0;32mfor\u001B[0m \u001B[0mfeature\u001B[0m \u001B[0;32min\u001B[0m \u001B[0manalyze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdoc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1277\u001B[0m                 \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1278\u001B[0m                     \u001B[0mfeature_idx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvocabulary\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mfeature\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py\u001B[0m in \u001B[0;36m_analyze\u001B[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001B[0m\n\u001B[1;32m    115\u001B[0m                 \u001B[0mdoc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mngrams\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdoc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstop_words\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 117\u001B[0;31m                 \u001B[0mdoc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mngrams\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdoc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    118\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mdoc\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py\u001B[0m in \u001B[0;36m_word_ngrams\u001B[0;34m(self, tokens, stop_words)\u001B[0m\n\u001B[1;32m    268\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mn\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmin_n\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmax_n\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_original_tokens\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    269\u001B[0m                 \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_original_tokens\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mn\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 270\u001B[0;31m                     \u001B[0mtokens_append\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mspace_join\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moriginal_tokens\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m \u001B[0;34m:\u001B[0m \u001B[0mi\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mn\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    271\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    272\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mtokens\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "plot_annotated_ngrams_fixed(train_texts, train_labels, n=2, n_terms=20)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T11:10:53.380311500Z",
     "start_time": "2024-02-22T11:10:35.109480700Z"
    }
   },
   "id": "b749a33cff5518b6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training\n",
    "\n",
    " We will use the `transformers` library to fine-tune a BERT model on the fake news detection task. We will use the `Trainer` class to handle the training loop and the `TrainingArguments` class to define the training configuration. We will also define a function to compute the evaluation metrics for the task. We will use the `precision`, `recall`, and `F1 score` as the evaluation metrics. We will then use the `optuna` library to perform hyperparameter optimization to find the best hyperparameters for the model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f75e233452e3dbeb"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "# check for cuda\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:06:54.009906800Z",
     "start_time": "2024-02-22T12:06:53.965312500Z"
    }
   },
   "id": "baccea00e333709d"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    eval_predictions, eval_labels = eval_pred\n",
    "    eval_predictions = np.argmax(eval_predictions, axis=1)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(eval_labels, eval_predictions, average='binary')\n",
    "    acc = accuracy_score(eval_labels, eval_predictions)\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:06:54.010403500Z",
     "start_time": "2024-02-22T12:06:54.009906800Z"
    }
   },
   "id": "25f4d17014cd8f38"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define hyperparameters for the trial\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True)\n",
    "    num_train_epochs = trial.suggest_int(\"num_train_epochs\", 1, 5)\n",
    "    per_device_train_batch_size = trial.suggest_categorical(\"per_device_train_batch_size\", [4, 8, 16, 32])\n",
    "    warmup_steps = trial.suggest_int(\"warmup_steps\", 0, 500)\n",
    "\n",
    "    # Create the model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, device_map=device)\n",
    "    # Define the training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=per_device_train_batch_size,\n",
    "        warmup_steps=warmup_steps,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        disable_tqdm=False,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "    )\n",
    "\n",
    "    # Create the trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate the model\n",
    "    metrics = trainer.evaluate()\n",
    "\n",
    "    # Return the metric to be optimized\n",
    "    return metrics['eval_f1']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-13T16:50:32.368823900Z"
    }
   },
   "id": "c5c7f330fd8e5fe1"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-13 18:50:32,375] A new study created in memory with name: no-name-342cecc5-ac91-445f-937f-4172e6d27c52\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='1827' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/1827 : < :, Epoch 0.00/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results\\checkpoint-609 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results\\checkpoint-1218 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='1015' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   1/1015 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-13 22:09:59,349] Trial 0 finished with value: 0.9702156795617939 and parameters: {'learning_rate': 2.142824278123738e-06, 'num_train_epochs': 3, 'per_device_train_batch_size': 4, 'warmup_steps': 42}. Best is trial 0 with value: 0.9702156795617939.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 2/77 : < :, Epoch 0.01/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='1015' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   1/1015 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-13 23:32:10,303] Trial 1 finished with value: 0.9678820436621328 and parameters: {'learning_rate': 4.1010951065515624e-05, 'num_train_epochs': 1, 'per_device_train_batch_size': 32, 'warmup_steps': 401}. Best is trial 0 with value: 0.9702156795617939.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='1220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/1220 : < :, Epoch 0.00/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='1015' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   1/1015 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 03:07:59,093] Trial 2 finished with value: 0.9676099556767814 and parameters: {'learning_rate': 1.3657461684292952e-06, 'num_train_epochs': 4, 'per_device_train_batch_size': 8, 'warmup_steps': 465}. Best is trial 0 with value: 0.9702156795617939.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 2/77 : < :, Epoch 0.01/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results\\checkpoint-77 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='1015' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   1/1015 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 04:33:27,656] Trial 3 finished with value: 0.9753727971079982 and parameters: {'learning_rate': 6.355343327602066e-05, 'num_train_epochs': 1, 'per_device_train_batch_size': 32, 'warmup_steps': 219}. Best is trial 3 with value: 0.9753727971079982.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='305' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  2/305 : < :, Epoch 0.00/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results\\checkpoint-305 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='1015' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   1/1015 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 05:46:29,582] Trial 4 finished with value: 0.9480374665477252 and parameters: {'learning_rate': 2.064649831052212e-06, 'num_train_epochs': 1, 'per_device_train_batch_size': 8, 'warmup_steps': 261}. Best is trial 3 with value: 0.9753727971079982.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='1525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/1525 : < :, Epoch 0.00/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results\\checkpoint-305 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results\\checkpoint-610 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results\\checkpoint-915 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results\\checkpoint-1220 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='1015' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   1/1015 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 10:09:00,443] Trial 5 finished with value: 0.9820730866467479 and parameters: {'learning_rate': 2.191598408839492e-06, 'num_train_epochs': 5, 'per_device_train_batch_size': 8, 'warmup_steps': 167}. Best is trial 5 with value: 0.9820730866467479.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 2/77 : < :, Epoch 0.01/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results\\checkpoint-77 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='1015' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   1/1015 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 11:35:28,150] Trial 6 finished with value: 0.8788920129126314 and parameters: {'learning_rate': 4.718101048666568e-06, 'num_train_epochs': 1, 'per_device_train_batch_size': 32, 'warmup_steps': 363}. Best is trial 5 with value: 0.9820730866467479.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='1525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/1525 : < :, Epoch 0.00/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results\\checkpoint-305 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results\\checkpoint-610 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results\\checkpoint-915 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results\\checkpoint-1220 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results\\checkpoint-1525 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='1015' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   1/1015 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 16:02:39,828] Trial 7 finished with value: 0.9825887743413516 and parameters: {'learning_rate': 1.2580246392963075e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 8, 'warmup_steps': 356}. Best is trial 7 with value: 0.9825887743413516.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='308' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  2/308 : < :, Epoch 0.01/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results\\checkpoint-77 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='1015' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   1/1015 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 20:07:25,233] Trial 8 finished with value: 0.9702496295451954 and parameters: {'learning_rate': 2.096683306604786e-06, 'num_train_epochs': 4, 'per_device_train_batch_size': 32, 'warmup_steps': 342}. Best is trial 7 with value: 0.9825887743413516.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='1525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/1525 : < :, Epoch 0.00/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results\\checkpoint-305 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results\\checkpoint-610 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results\\checkpoint-915 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results\\checkpoint-1220 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results\\checkpoint-1525 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='1015' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   1/1015 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-15 02:07:07,327] Trial 9 finished with value: 0.980747192298877 and parameters: {'learning_rate': 6.778688081449428e-06, 'num_train_epochs': 5, 'per_device_train_batch_size': 8, 'warmup_steps': 318}. Best is trial 7 with value: 0.9825887743413516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: 7\n",
      "Best value (F1 score): 0.9825887743413516\n",
      "Best hyperparameters: {'learning_rate': 1.2580246392963075e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 8, 'warmup_steps': 356}\n"
     ]
    }
   ],
   "source": [
    "# Create the study and run the optimization\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "print(f\"Best trial: {study.best_trial.number}\")\n",
    "print(f\"Best value (F1 score): {study.best_value}\")\n",
    "print(f\"Best hyperparameters: {study.best_params}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-13T16:50:32.374823300Z"
    }
   },
   "id": "27b78e94d0f6ea9a"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Embedding(50267, 768)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, device_map=device)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:06:54.728261300Z",
     "start_time": "2024-02-22T12:06:54.009906800Z"
    }
   },
   "id": "d22c52bc6c67e643"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "learning_rate = 1.2580246392963075e-05\n",
    "num_train_epochs = 5\n",
    "per_device_train_batch_size = 8\n",
    "warmup_steps = 356\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./API/results',\n",
    "    logging_dir='./API/logs',\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=2e-5,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    disable_tqdm=False,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:06:55.019422400Z",
     "start_time": "2024-02-22T12:06:54.728261300Z"
    }
   },
   "id": "6e2e5888968d361e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mchen24201\u001B[0m (\u001B[33mapi-project\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112629666846867, max=1.0…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "952620420d6b4ea18f95d75f4f0677e1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.16.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.2"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/porat/wandb/run-20240222_140658-xy9kqwgu</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/api-project/huggingface/runs/xy9kqwgu' target=\"_blank\">lucky-firecracker-3</a></strong> to <a href='https://wandb.ai/api-project/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/api-project/huggingface' target=\"_blank\">https://wandb.ai/api-project/huggingface</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/api-project/huggingface/runs/xy9kqwgu' target=\"_blank\">https://wandb.ai/api-project/huggingface/runs/xy9kqwgu</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='9135' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/9135 : < :, Epoch 0.00/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./API/results/checkpoint-3045 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "history = trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-02-22T12:06:55.236399100Z"
    }
   },
   "id": "2a2152af67f6f3f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Evaluation\n",
    "\n",
    " We will evaluate the trained model on the test set. We will use the `evaluate` method of the `Trainer` class to compute the evaluation metrics on the test set. We will also use the `predict` method to generate predictions on the test set and compute the confusion matrix to visualize the model's performance."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afeaa38b55b2e82c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluation on the test set\n",
    "results = trainer.evaluate(test_dataset)\n",
    "print(results)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ade3d900c0ada213"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "predictions, labels, _ = trainer.predict(test_dataset)\n",
    "predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(labels, predictions)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "dc77935426baa9ca"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Conclusion\n",
    "\n",
    " In this notebook, we used the `transformers` library to fine-tune a BERT model on the fake news detection task. We used the `optuna` library to perform hyperparameter optimization to find the best hyperparameters for the model. We then evaluated the trained model on the test set and visualized its performance using a confusion matrix. The model achieved an accuracy of 0.98 on the test set, demonstrating its effectiveness in detecting fake news."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73f7ae83f99c9f38"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "('model\\\\tokenizer_config.json',\n 'model\\\\special_tokens_map.json',\n 'model\\\\vocab.txt',\n 'model\\\\added_tokens.json',\n 'model\\\\tokenizer.json')"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"./model\"\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T14:08:59.045104700Z",
     "start_time": "2024-02-16T14:08:58.656143800Z"
    }
   },
   "id": "bef5ca9e3ca6b190"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a506ab39d5772080"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
